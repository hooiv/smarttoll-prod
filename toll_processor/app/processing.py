import logging
import time
import json
from typing import Dict, Any, Optional
from math import radians, cos, sin, asin, sqrt

from pydantic import ValidationError

from app.models import GpsData, VehicleState, TollEvent
from app.config import settings
from app import state as vehicle_state_manager # Renamed import for clarity
from app import database as db_manager # Renamed import for clarity
from app import kafka_client

log = logging.getLogger(__name__)

def calculate_distance_haversine(lat1: float, lon1: float, lat2: float, lon2: float) -> float:
    """
    Calculates the great-circle distance between two points
    on the earth (specified in decimal degrees) using Haversine formula.
    Returns distance in kilometers.
    """
    if None in [lat1, lon1, lat2, lon2]:
        log.warning("Cannot calculate distance with missing coordinates.")
        return 0.0

    # Convert decimal degrees to radians
    lon1_rad, lat1_rad, lon2_rad, lat2_rad = map(radians, [lon1, lat1, lon2, lat2])

    # Haversine formula
    dlon = lon2_rad - lon1_rad
    dlat = lat2_rad - lat1_rad
    a = sin(dlat/2)**2 + cos(lat1_rad) * cos(lat2_rad) * sin(dlon/2)**2
    c = 2 * asin(sqrt(a))

    # Radius of earth in kilometers. Use 6371 for kilometers.
    km = 6371 * c
    return km

# Placeholder for potentially more complex distance calculation using PostGIS
# def calculate_distance_postgis(lat1, lon1, lat2, lon2) -> float:
#     # Requires snapping points to road network and calculating length along geometry
#     log.warning("PostGIS distance calculation not implemented yet.")
#     return calculate_distance_haversine(lat1, lon1, lat2, lon2) # Fallback


def handle_zone_entry(vehicle_id: str, device_id: str, zone_id: str, rate: float, timestamp_ms: int, lat: float, lon: float):
    """Handles logic when a vehicle enters a zone."""
    log.info(f"Vehicle {vehicle_id} (Device: {device_id}) ENTERED toll zone {zone_id} at rate {rate}/km.")
    new_state = VehicleState(
        in_zone=True,
        zone_id=zone_id,
        rate_per_km=rate,
        entry_time=timestamp_ms,
        distance_km=0.0,
        lat=lat, # Store first position inside zone
        lon=lon,
        last_update=timestamp_ms,
        deviceId=device_id
    )
    vehicle_state_manager.update_vehicle_state(vehicle_id, new_state)
    # METRICS: Increment zone entry counter (metric_name='zone_entries_total', labels={'zone_id': zone_id})

def handle_zone_exit(vehicle_id: str, device_id: str, last_state: VehicleState, exit_timestamp_ms: int, exit_lat: float, exit_lon: float):
    """Handles logic when a vehicle exits a zone, calculates toll, sends event."""
    log.info(f"Vehicle {vehicle_id} (Device: {device_id}) EXITED toll zone {last_state.zone_id}.")
    try:
        # Calculate distance for the final segment (from last known point inside to current point outside)
        if settings.DISTANCE_CALC_METHOD == 'postgis':
            # final_distance_segment = calculate_distance_postgis(last_state.lat, last_state.lon, exit_lat, exit_lon)
            final_distance_segment = calculate_distance_haversine(last_state.lat, last_state.lon, exit_lat, exit_lon) # Fallback for now
        else: # Default to haversine
             final_distance_segment = calculate_distance_haversine(last_state.lat, last_state.lon, exit_lat, exit_lon)

        total_distance = last_state.distance_km + final_distance_segment

        # Basic validation on distance
        if total_distance < 0:
            log.warning(f"Calculated negative total distance ({total_distance}km) for {vehicle_id} exiting {last_state.zone_id}. Setting to 0.")
            total_distance = 0.0
        elif total_distance > 1000: # Arbitrary sanity check for a single toll segment
             log.warning(f"Calculated unusually large distance ({total_distance}km) for {vehicle_id} exiting {last_state.zone_id}.")

        rate = last_state.rate_per_km
        toll_amount = total_distance * rate

        # Use Decimal for financial calculations if high precision needed
        # from decimal import Decimal, ROUND_HALF_UP
        # toll_amount_decimal = (Decimal(str(total_distance)) * Decimal(str(rate))).quantize(Decimal("0.01"), rounding=ROUND_HALF_UP)
        # toll_amount = float(toll_amount_decimal)

        toll_amount = round(toll_amount, 2) # Round to 2 decimal places

        # Generate toll event payload using Pydantic model for structure and validation
        toll_event = TollEvent(
            # eventId is generated by default factory
            vehicleId=vehicle_id,
            deviceId=last_state.deviceId, # Use the device ID stored in the state
            zoneId=last_state.zone_id,
            entryTime=last_state.entry_time,
            exitTime=exit_timestamp_ms,
            distanceKm=round(total_distance, 3),
            ratePerKm=rate,
            tollAmount=toll_amount,
            currency="USD", # Get from config or zone data in future
            processedTimestamp=int(time.time() * 1000)
        )

        # Publish the toll event to Kafka
        # success = kafka_client.send_message(settings.TOLL_EVENT_TOPIC, toll_event.dict(), key=vehicle_id.encode('utf-8')) # Pydantic V1
        success = kafka_client.send_message(settings.TOLL_EVENT_TOPIC, toll_event.model_dump(), key=vehicle_id.encode('utf-8')) # Pydantic V2, key ensures events for same vehicle go to same partition

        if success:
            log.info(f"Published Toll Event: ID={toll_event.eventId}, Vehicle={vehicle_id}, Zone={toll_event.zoneId}, Amount={toll_event.tollAmount:.2f} {toll_event.currency}, Dist={toll_event.distanceKm:.3f}km")
            # METRICS: Increment successful toll events counter (metric_name='toll_events_published_total', labels={'zone_id': last_state.zone_id})
            # METRICS: Record toll amount histogram (metric_name='toll_amount_usd_histogram', value=toll_amount, labels={'zone_id': last_state.zone_id})
        else:
            log.error(f"Failed to publish Toll Event for Vehicle {vehicle_id}, Zone {last_state.zone_id}. Event ID: {toll_event.eventId}")
            # Implement retry logic or dead-letter queue for critical billing events if needed
            kafka_client.publish_error(
                error_type="KafkaPublishError",
                message=f"Failed to publish TollEvent to {settings.TOLL_EVENT_TOPIC}",
                context={"vehicle_id": vehicle_id, "event_id": toll_event.eventId}
            )

    except Exception as e:
        log.exception(f"Error during zone exit handling for {vehicle_id}: {e}")
        kafka_client.publish_error(
            error_type="ZoneExitHandlingError",
            message=str(e),
            exc=e,
            context={"vehicle_id": vehicle_id, "last_state": last_state.model_dump() if last_state else None} # Pydantic V2
            # context={"vehicle_id": vehicle_id, "last_state": last_state.dict() if last_state else None} # Pydantic V1
        )

    finally:
        # Always clear the state after processing exit attempt
        # If event publishing *must* succeed, need a more complex retry/outbox pattern
        deleted = vehicle_state_manager.update_vehicle_state(vehicle_id, None)
        if deleted:
            log.debug(f"Cleared state for vehicle {vehicle_id} after exiting zone.")
        else:
             log.warning(f"Failed to clear state for vehicle {vehicle_id} after exiting zone.")


def process_gps_message(message_value: Dict[str, Any], message_offset: int = -1) -> bool:
    """
    Processes a single GPS message dict.

    Args:
        message_value: The dictionary payload from Kafka.
        message_offset: The Kafka offset of the message (for logging).

    Returns:
        True if processing was successful (or skipped gracefully), False otherwise (signals potential retry).
    """
    processing_start_time = time.monotonic()
    log.debug(f"Processing message at offset {message_offset}: {message_value}")

    # --- 1. Validation and Parsing ---
    try:
        # TODO: Decryption step would go here if payload is encrypted
        gps_data = GpsData(**message_value)
        log.debug(f"Validated GPS data for vehicle {gps_data.vehicleId}")

    except ValidationError as e:
        log.warning(f"Invalid GPS data format at offset {message_offset}. Error: {e.errors()}. Message: {message_value}")
        kafka_client.publish_error(
            error_type="ValidationError",
            message=f"Invalid GPS data format: {e.errors()}",
            original_msg=message_value,
            context={"offset": message_offset}
        )
        return True # Skip invalid message, commit offset
    except Exception as e:
        log.exception(f"Unexpected error parsing/validating message at offset {message_offset}: {message_value}")
        kafka_client.publish_error(
            error_type="ParsingError",
            message=str(e),
            exc=e,
            original_msg=message_value,
            context={"offset": message_offset}
        )
        return True # Skip unparseable message

    # Extract key fields after validation
    vehicle_id = gps_data.vehicleId
    device_id = gps_data.deviceId
    lat = gps_data.latitude
    lon = gps_data.longitude
    timestamp_ms = gps_data.timestamp

    # --- 2. Get Current State & Location Info ---
    # These return None on error, handled within the functions
    last_state = vehicle_state_manager.get_vehicle_state(vehicle_id)
    current_zone_info = db_manager.get_current_toll_zone(lat, lon) # Uses DB pool

    # --- 3. State Machine Logic ---
    try:
        if current_zone_info:
            # Inside a toll zone
            current_zone_id = current_zone_info["zone_id"]
            current_rate = current_zone_info["rate_per_km"]

            if last_state and last_state.in_zone:
                # Previously inside a zone
                if last_state.zone_id == current_zone_id:
                    # Still in the *same* zone: Accumulate distance
                    distance_segment = calculate_distance_haversine(last_state.lat, last_state.lon, lat, lon)
                    last_state.distance_km += distance_segment
                    last_state.lat = lat
                    last_state.lon = lon
                    last_state.last_update = timestamp_ms
                    # Update device ID if it changed? Usually shouldn't for same vehicle state.
                    # last_state.deviceId = device_id
                    vehicle_state_manager.update_vehicle_state(vehicle_id, last_state)
                    log.debug(f"Vehicle {vehicle_id} moved within {current_zone_id}. Dist: {last_state.distance_km:.3f} km")
                else:
                    # Moved directly to a *different* zone: Exit old, Enter new
                    log.info(f"Vehicle {vehicle_id} moved from {last_state.zone_id} to {current_zone_id}")
                    # Exit previous zone using current point as the segment end
                    handle_zone_exit(vehicle_id, device_id, last_state, timestamp_ms, lat, lon)
                    # Enter the new zone
                    handle_zone_entry(vehicle_id, device_id, current_zone_id, current_rate, timestamp_ms, lat, lon)
            else:
                # Entered a zone (was outside or first message for this vehicle)
                handle_zone_entry(vehicle_id, device_id, current_zone_id, current_rate, timestamp_ms, lat, lon)
        else:
            # Outside a toll zone
            if last_state and last_state.in_zone:
                # Just exited a toll zone
                handle_zone_exit(vehicle_id, device_id, last_state, timestamp_ms, lat, lon)
            else:
                # Still outside, do nothing (state already cleared or never existed)
                 log.debug(f"Vehicle {vehicle_id} remains outside toll zones.")
                 # Optionally ensure state is cleared if it exists but indicates outside (shouldn't happen with current logic)
                 # if last_state: vehicle_state_manager.update_vehicle_state(vehicle_id, None)

        # --- 4. Processing Successful ---
        processing_duration = time.monotonic() - processing_start_time
        log.debug(f"Successfully processed message for {vehicle_id} at offset {message_offset} in {processing_duration:.4f}s")
        # METRICS: Record processing time histogram (metric_name='gps_processing_duration_seconds')
        return True

    except Exception as e:
        # Catch errors during core logic processing
        log.exception(f"Core logic error processing message for {vehicle_id} at offset {message_offset}.")
        kafka_client.publish_error(
            error_type="ProcessingLogicError",
            message=str(e),
            exc=e,
            original_msg=message_value,
            context={"vehicle_id": vehicle_id, "last_state": last_state.model_dump() if last_state else None} # V2
            # context={"vehicle_id": vehicle_id, "last_state": last_state.dict() if last_state else None} # V1
        )
        # Decide whether to commit offset (True = skip message, False = retry potentially)
        # For persistent logic errors, True is often better to avoid blocking partition
        return True # Commit offset even if logic fails, to avoid poison pills
